{"name":"Raft Light","tagline":"Simple, easy to use stream computation library for C++.","body":"### Welcome to the Raft Light C++ template library\r\nTo checkout the library do the following:\r\n```\r\n$ cd location_for_the_repo\r\n$ git clone git@github.com:jonathan-beard/RaftLight.git\r\n$ cd RaftLight\r\n$ make\r\n$ sudo make install\r\n```\r\n\r\nThis will generate the static library file _raftlight.a_.  When building an application\r\nusing the library the only header file needed is the _raft_ header.  Once the library\r\nis build you're basically set save for a few details, which will be laid out within the tutorial\r\n as we go through the example we're about to build.\r\n\r\n\r\nTo build the example application simply:\r\n```\r\n$ cd RaftLight/ExampleApps\r\n$ make\r\n```\r\n\r\n\r\n\r\n### Authors and Contributors\r\nIn 2013 Jonathan Beard (@jonathan-beard) started work on the Raft language.  In the interim,\r\nand realizing the ubiquity of the C++ language, he started work on a template library that \r\nuses the same framework as the full Raft language and run-time system.  This C++ library is \r\nthe result.\r\n\r\n### Genealogy\r\nThere have been several dozen streaming languages.  Most notable of which is probably StreaMIT.  I've worked on the Auto-Pipe streaming runtime system (both versions 1 and 2) developed at Washington University.  This particular streaming library was developed as a faster way to get started with stream processing by enabling users to stick to a language with which they are already familiar (C++).\r\n\r\n### Tutorial\r\nThe tutorial could be written two ways.  The first would be to enumerate all the possible functions and configurations.  The second would be to give an example and explain the example as it is presented.  We'll start with the example approach then move to a short directory of useful functions followed by some permutations on the previously mentioned example.\r\n\r\nFirst and foremost what is stream processing?  Essentially it is a compute paradigm that envisions perfectly safe, threaded programs (although we'll relax this a bit with locked shared objects, shown much later in the tutorial).  Stream programs themselves are decomposed into compute \"kernels\" which are connected by communications links called \"streams.\"  As an extremely simple example, take a look at the figure below which has three compute \"kernels\" (A,B,C) connected by two \"streams.\"\r\n\r\n![tandem queue](http://www.cse.wustl.edu/~beardj/queues.jpg)\r\n\r\nAs a concrete example we have a \"sum\" application which generates a random stream of numbers from two separate threads, sums them in another and finally prints them in yet another thread.  Admittedly this is a bit wasteful in practice, however its a nice dirt simple example. \r\n\r\n```c++\r\n#include <cassert>\r\n#include <iostream>\r\n#include <cstdint>\r\n#include <cstdlib>\r\n/** include the raft header file **/\r\n#include <raft>\r\n\r\n\r\ntemplate < typename T > class Generate : public Kernel\r\n{\r\npublic:\r\n   Generate( std::int64_t count = 1000 ) : Kernel(),\r\n                                          count( count )\r\n   {\r\n      output.addPort< T >( \"number_stream\" );\r\n   }\r\n\r\n   virtual raft::kstatus run()\r\n   {\r\n      if( count-- > 1 )\r\n      {\r\n         output[ \"number_stream\" ].push( count );\r\n         return( raft::proceed );\r\n      }\r\n      output[ \"number_stream\" ].push( count, raft::eof );\r\n      return( raft::stop );\r\n   }\r\n\r\nprivate:\r\n   std::int64_t count;\r\n};\r\n\r\ntemplate< typename A, typename B, typename C > class Sum : public Kernel\r\n{\r\npublic:\r\n   Sum() : Kernel()\r\n   {\r\n      input.addPort< A >( \"input_a\" );\r\n      input.addPort< B >( \"input_b\" );\r\n      output.addPort< C  >( \"sum\" );\r\n   }\r\n   \r\n   virtual raft::kstatus run()\r\n   {\r\n      A a;\r\n      B b;\r\n      raft::signal  sig_a( raft::none  ), sig_b( raft::none );\r\n      input[ \"input_a\" ].pop( a, &sig_a );\r\n      input[ \"input_b\" ].pop( b, &sig_b );\r\n      assert( sig_a == sig_b );\r\n      C c( a + b );\r\n      output[ \"sum\" ].push( c , sig_a );\r\n      if( sig_b == raft::eof )\r\n      {\r\n         return( raft::stop );\r\n      }\r\n      return( raft::proceed );\r\n   }\r\n\r\n};\r\n\r\ntemplate< typename T > class Print : public Kernel\r\n{\r\npublic:\r\n   Print() : Kernel()\r\n   {\r\n      input.addPort< T >( \"in\" );\r\n   }\r\n\r\n   virtual raft::kstatus run()\r\n   {\r\n      T data;\r\n      raft::signal  signal( raft::none );\r\n      input[ \"in\" ].pop( data, &signal );\r\n      fprintf( stderr, \"%\" PRIu64 \"\\n\", data );\r\n      if( signal == raft::eof )\r\n      {\r\n         return( raft::stop );\r\n      }\r\n      return( raft::proceed );\r\n   }\r\n};\r\n\r\nint\r\nmain( int argc, char **argv )\r\n{\r\n   Map map;\r\n   auto linked_kernels( map.link( new Generate< std::int64_t >(),\r\n                                  new Sum< std::int64_t,std::int64_t, std::int64_t >(),\r\n                                  \"input_a\" ) );\r\n   map.link( new Generate< std::int64_t >(), &( linked_kernels.dst ), \"input_b\" );\r\n   map.link( &( linked_kernels.dst ), new Print< std::int64_t >() );\r\n   map.exe();\r\n   return( EXIT_SUCCESS );\r\n}\r\n```\r\n\r\nThe first thing to notice is that all compute kernels extend the class Kernel.  This sets up the \"ports\"\r\nthat exist for communication between compute kernels.  For each kernel there are multiple ports.  Input\r\nports and output ports for each kernel are maintained in a data structure of that name.  When designing \r\na new kernel, the constructor must declare all ports as such:\r\n\r\n```c++\r\n   [input | output].addPort< [type] >( [port name] );\r\n```\r\n\r\nThis has two effects, the first registering a type with the port to ensure type safety, and the second\r\nregistering a port with a name so that it can be quickly accessed later.  These ports are constructed\r\nas lock free first in, first out buffers or \"ring-buffers\" which enable communication.  The run-time\r\nsystem decides on how big the buffer should be and has the option of dynamically monitoring the buffer\r\nto adjust the size at run-time.  Once ports are declared within the constructor the second function that\r\nmust be declared is _run()_.  It performs the main work of the kernel, although sub-functions can be \r\ndeclared to compartmentalize code.  As an example:\r\n\r\n```c++\r\n   virtual raft::kstatus run()\r\n   {\r\n      if( [ some bool here ] )\r\n      {\r\n         output[ \"the_port\" ].push( count );\r\n         /** return raft::proceed to get called again **/\r\n         return( raft::proceed );\r\n      }\r\n      /** else **/\r\n      /** \r\n       * call push with the last item and send a signal that will terminate\r\n       * the application such as raft::eof\r\n       */\r\n      output[ \"the_port\" ].push( count, raft::eof );\r\n      /** return raft::stop to end the calling of this kernel **/\r\n      return( raft::stop );\r\n   }\r\n```\r\n\r\nThe run function can be executed in a separate thread or in it's own process depending \r\non how the scheduler schedules it.  In either case, it will be called until it returns\r\nraft::stop, otherwise raft::proceed should be returned.  Otherwise there is nothing\r\nreally special about the Kernel class.  In future tutorials I'll add an example of how\r\nthe RaftLight library system an be used with OpenCL with the queue talking directly to\r\na kernel running on a GPU.  GPU kernels will have a slightly differing structure, but \r\nfrom the programmers perspective will have similar port semantics as the C++ kernels.\r\n\r\nTo \"hook\" compute kernels together we need a \"Map\" object, as in the following example (shamelessly taken\r\nfrom the above \"sum\" example):\r\n```c++\r\nint\r\nmain( int argc, char **argv )\r\n{\r\n   Map map;\r\n   auto linked_kernels( map.link( new Generate< std::int64_t >(),\r\n                                  new Sum< std::int64_t,std::int64_t, std::int64_t >(),\r\n                                  \"input_a\" ) );\r\n   map.link( new Generate< std::int64_t >(), &( linked_kernels.dst ), \"input_b\" );\r\n   map.link( &( linked_kernels.dst ), new Print< std::int64_t >() );\r\n   map.exe();\r\n   return( EXIT_SUCCESS );\r\n}\r\n```\r\n\r\nUsing the _link()_ function we can link together compatible combinations of two compute kernels.  Compatible\r\nports will have the same type or will be able to be cast to the same type. The _link()_ function returns a\r\nreference to the functions that are passed as parameters.  This is a convenience so that the programmer can\r\ninstantiate them via the function param with _new_ and use the return values for follow-on _link()_ calls.  This\r\nfunction has various forms as follows:\r\n```c++\r\n/**\r\n * version 1: Kernel's a & b are assumed to have a single output\r\n * and input port respectively, otherwise an exception is thrown.   \r\n */\r\ntemplate < order::spec t = order::in >\r\n      kernel_pair_t link( Kernel *a, Kernel *b );\r\n/**\r\n * version 2: Kernel a has multiple output ports, but one named _a\\_port_, Kernel\r\n * b has a single input port otherwise an exception is thrown.\r\n */\r\ntemplate < order::spec t = order::in > \r\n      kernel_pair_t link( Kernel *a, const std::string  a_port, Kernel *b );\r\n/** \r\n * version 3: Kernel a has a single output port (otherwise an exception is thrown,\r\n * Kernel b has multiple input ports with at least one named _b\\_port_\r\n */\r\ntemplate < order::spec t = order::in >\r\n      kernel_pair_t link( Kernel *a, Kernel *b, const std::string b_port );\r\n/**\r\n * version 4: both kernels have multiple output ports with at least one named _a\\_port_ \r\n * and _b\\_port_, otherwise an exception is thrown.\r\n */\r\ntemplate < order::spec t = order::in >\r\n      kernel_pair_t link( Kernel *a, const std::string a_port, \r\n                          Kernel *b, const std::string b_port );\r\n```","google":"UA-55176313-1","note":"Don't delete this file! It's used internally to help with page regeneration."}